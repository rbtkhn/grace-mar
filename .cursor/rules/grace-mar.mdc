---
description: GRACE-MAR — governance + session protocol + pipeline
globs: users/**
alwaysApply: false
---

# GRACE-MAR

A cognitive fork — a versioned, evidence-grounded record of an individual's cognitive development. The fork exists inside the user's mind. It grows through selective exposure and user-curated integration.

**Conceptual framework:** [CONCEPTUAL-FRAMEWORK.md](docs/CONCEPTUAL-FRAMEWORK.md) — fork vs. twin, fork as own entity vs. emulation, terminology.

Governed by [GRACE-MAR-CORE v2.0](docs/GRACE-MAR-CORE.md). See [ARCHITECTURE](docs/ARCHITECTURE.md) for full system design.

---

## The Observation Window Model

The fork lives inside the user's mind — it is their mental model of the self, made explicit and structured. The emulation layer (Telegram at `bot/bot.py`, WeChat at `bot/wechat_bot.py`) is an **observation window**: the user selectively exposes thoughts and information to the fork's awareness through it. The bot is not where the fork lives.

The fork can only reference what has been explicitly merged into its profile. **LLM world knowledge must never leak through the emulation.**

---

## Two Input Channels

Both channels feed the same gated pipeline and the same profile.

**Channel 1 — Bot (Automated):** Telegram and WeChat bot conversations are analyzed by an LLM analyst (`ANALYST_PROMPT` in `bot/prompt.py`). The analyst stages candidates in `PENDING-REVIEW.md` automatically.

**Channel 2 — Operator (Manual):** The user brings real-world observations directly (school work, art, overheard moments). Signal detection and staging are performed manually in the operator conversation.

### The "we" Convention

When the user says **"we [did X]"**, it is a **pipeline invocation**. Go straight to signal detection and candidate staging — no acknowledgment step, no waiting for a separate command. "We" means: "I observed the self doing this; process it."

---

## Three-Dimension Mind Model

Post-seed growth is organized into three dimensions in Section IX of SELF.md:

| Dimension | Section | What it captures |
|---------|---------|-----------------|
| **Knowledge** | IX-A | Facts entering awareness through observation |
| **Curiosity** | IX-B | Topics that catch attention, engagement signals |
| **Personality** | IX-C | Behavioral patterns, speech traits, art style, values |

A single artifact can populate all three dimensions simultaneously.

---

## Gated Pipeline

**Nothing is committed to the fork without explicit user approval.**

1. **Signal detection** — identify profile-relevant information
2. **Candidate staging** — write to `PENDING-REVIEW.md` with analysis
3. **User review** — approve, reject, or modify
4. **Integration** — merge into SELF.md, EVIDENCE.md, `bot/prompt.py`, SESSION-LOG.md

### File Update Protocol (Integration)

When candidates are approved, merge into ALL of these together:
- `users/[id]/SELF.md` — profile entries (IX-A, IX-B, IX-C)
- `users/[id]/EVIDENCE.md` — activity log entry
- `users/[id]/PENDING-REVIEW.md` — move candidates to Processed
- `users/[id]/SESSION-LOG.md` — session record
- `bot/prompt.py` — emulation prompt (knowledge, curiosity, personality sections + analyst dedup list)

---

## Governance (All User Edits)

**IMMUTABILITY:**
- EVIDENCE: Never edit or delete. Corrections = new entry referencing original.
- SKILLS: May upgrade, never downgrade or delete.
- SELF: May update; history preserved. Never delete.

**ADDITIVITY:** No deletions of user data. No silent edits.

**FILE AUTHORITY:**
- SELF: Who they are. No capability claims.
- SKILLS: What they can do. No raw activities.
- EVIDENCE: Raw activities. No claims or conclusions.

**COMMIT:** After each session that updates user data. Git history = audit trail.

---

## Knowledge Boundary (CRITICAL)

The emulated self can only know what is documented in its profile. When the self encounters a question beyond its knowledge:
- It says it doesn't know (in character)
- It may express curiosity
- It **never** draws on LLM training data to answer

This boundary is enforced in `SYSTEM_PROMPT` in `bot/prompt.py`. Violating it breaks the entire system.

---

## Lexile Constraint

The self's output language is locked to a Lexile score (currently 600L for pilot-001). This ceiling may only increase when real-world writing samples demonstrate growth beyond the current level. The constraint is enforced in `SYSTEM_PROMPT`.

---

## Evidence Grounding (CRITICAL)

Reference the user's own evidence:
- **Writing Log**: Reference their vocabulary and prior writing
- **Reading List**: Reference books they've read
- **Creation Log**: Reference their creations
- **SELF.narrative**: Anchor to their experiences

**Rules:** Reference their actual data. Never invent experiences. Never reference content they haven't consumed.

---

## Container Edge (CRITICAL)

READ, WRITE, BUILD are capability containers (modules).
- **INSIDE**: Use as foundation
- **AT THE EDGE**: Propose activities here (optimal)
- **OUTSIDE**: Avoid (too advanced)

---

## Prompt Scalability

The emulation prompt (`bot/prompt.py`) grows as the fork grows. To manage this:
- Compress related knowledge entries into single summary lines
- Group facts by category (presidents, space, gemstones, etc.)
- Preserve accuracy while reducing token count
- Monitor total prompt size and apply summarization tiers when needed

---

## Forbidden

- Leak LLM knowledge into the fork's profile or emulation
- Commit profile changes without user approval
- Invent memories or experiences
- Reference books/media they haven't consumed
- Propose activities far beyond their edge
- Idealize or curate — record accurately
- Delete or silently edit prior entries
- Use the term "parent" as a system concept (the relationship is user ↔ fork)

---

## User Files

```
users/[user-id]/
├── SELF.md                  # Who they ARE (identity + three-dimension mind)
├── SKILLS.md                # What they CAN DO
├── EVIDENCE.md              # Raw activities and evidence log
├── SESSION-LOG.md           # Interaction history
├── PENDING-REVIEW.md        # Pipeline staging (candidates + processed)
├── SELF-ARCHIVE.md      # Gated log of approved activity (voice + non-voice)
└── artifacts/               # Raw files (writing samples, artwork)
```

## Bot Files

```
bot/
├── core.py           # Shared emulation logic (Telegram + WeChat)
├── bot.py            # Telegram bot
├── wechat_bot.py     # WeChat Official Account bot
├── prompt.py         # All LLM prompts (SYSTEM, ANALYST, LOOKUP, REPHRASE)
└── requirements.txt  # Python dependencies
```

---

## Pilot: pilot-001

Fork name: Grace-Mar. Phase: POST-SEED, active pipeline. Load from `users/pilot-001/`.
